# current version of ppprovider
# C:\Users\slee\AppData\Roaming\QGIS\QGIS3\profiles\default\python\plugins\pandapower-qgis

from qgis.core import QgsVectorDataProvider, QgsVectorLayer, QgsFeature, QgsField, QgsFields, \
    QgsGeometry, QgsPointXY, QgsLineString, QgsWkbTypes, QgsProject, QgsCoordinateReferenceSystem, \
    QgsFeatureRequest, QgsFeatureIterator, QgsFeatureSource, QgsAbstractFeatureSource, QgsFeatureSink, \
    QgsDataProvider, QgsProviderRegistry, QgsRectangle
from qgis.PyQt.QtCore import QMetaType
import json
import pandas as pd
import pandapower as pp
import pandapipes as ppi
from . import pandapower_feature_iterator, pandapower_feature_source
from .network_container import NetworkContainer


def convert_dtype_to_qmetatype(dtype):
    """
    Converts a pandas data type (dtype) to a corresponding Qt data type (QMetatype).
    Note: It does not convert actual values. It just returns the corresponding Qt data type for the given pandas data type.

    :param dtype: The pandas data type to convert.
    :type dtype: pandas dtype
    :return: The corresponding QMetaType type.
    :rtype: QMetaType
    """
    '''
    # Check if dtype is pandas Index object
    if isinstance(dtype, pd.Index):
        # Check data type of index
        index_dtype_str = str(dtype.dtype)
        print(f"Processing pandas Index with dtype: {index_dtype_str}")
        # ì •ìˆ˜í˜• ì¸ë±ìŠ¤ì¸ ê²½ìš°ì—ë„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤
        # ì´ëŠ” ë¶ˆì—°ì†ì ì¸ ì¸ë±ìŠ¤ë‚˜ ë²”ìœ„ê°€ í° ì¸ë±ìŠ¤ë¥¼ ì²˜ë¦¬í•  ë•Œ ë” ì•ˆì •ì ì…ë‹ˆë‹¤
        # int format index can occur problem: when the index is discontinuous or large
        return QMetaType.QString

    # int64 can occur problem in QGIS
    if pd.api.types.is_integer_dtype(dtype):
        dtype_str = str(dtype)
        if 'int64' in dtype_str or 'uint64' in dtype_str:
            print(f"Converting 64-bit integer type {dtype} to QString for better compatibility.")
            return QMetaType.QString
        return QMetaType.Int
    '''

    if pd.api.types.is_integer_dtype(dtype):
        return QMetaType.Int
    elif pd.api.types.is_unsigned_integer_dtype(dtype):
        return QMetaType.UInt
    elif pd.api.types.is_float_dtype(dtype):
        return QMetaType.Double
    elif pd.api.types.is_bool_dtype(dtype):
        return QMetaType.Bool
    elif pd.api.types.is_string_dtype(dtype):
        return QMetaType.QString
    elif pd.api.types.is_object_dtype(dtype):   # object is string?
        return QMetaType.QString
    elif pd.api.types.is_datetime64_any_dtype(dtype):
        return QMetaType.QDateTime
    else:
        print(f"Unexpected dtype detected: {dtype}. Add it or check if it is not available.")
        return QMetaType.Invalid


class PandapowerProvider(QgsVectorDataProvider):
    @classmethod
    def createProvider(cls, uri, providerOptions = QgsDataProvider.ProviderOptions(), flags = QgsDataProvider.ReadFlags()):
        """Factory methode that create provider instance"""
        return PandapowerProvider(uri, providerOptions, flags)


    def __init__(self, uri = "", providerOptions = QgsDataProvider.ProviderOptions(), flags = QgsDataProvider.ReadFlags()):
        super().__init__(uri)
        # Bring metadata instace from registry
        metadata_provider = QgsProviderRegistry.instance().providerMetadata("PandapowerProvider")
        self.uri = uri
        self.uri_parts = metadata_provider.decodeUri(uri)
        self._provider_options = providerOptions
        self._flags = flags

        # ğŸ”„ í•œ ë²ˆë§Œ ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print("=" * 50)
        print("pandapower_provider.py, init method")
        print(f"[DEBUG] Getting network data from container with URI: {uri}")
        # Bring network data from container
        network_data = NetworkContainer.get_network(uri)
        if network_data is None:
            print(f"[DEBUG] Failed to get network data from container")
            self._is_valid = False
            print("Warning: Failed to load Network data from Network container.\n")
            return
        else:
            print(f"[DEBUG] Successfully got network data from container")
            print(f"[DEBUG] Network data keys: {list(network_data.keys())}")

        # Setting network data
        self.net = network_data['net']
        print(f"\n[DEBUG] Network object type: {type(self.net)}")
        print(f"[DEBUG] Network object keys: {list(self.net.keys()) if hasattr(self.net, 'keys') else 'No keys method'}")
        print("[DEBUG] value of net: ", self.net)

        if self.uri_parts['network_type'] in ['bus', 'line']:
            self.vn_kv = network_data['vn_kv']
        elif self.uri_parts['network_type'] in ['junction', 'pipe']:
            self.pn_bar = network_data['pn_bar']
        else:
            raise ValueError("Invalid network_type. Expected 'bus', 'line', 'junction', 'pipe'.")  # necessary?
        self.network_type = self.uri_parts['network_type']
        self.type_layer_name = network_data['type_layer_name']

        print(f"\nType of layer name: {self.type_layer_name}")
        print(f"Network type: {self.network_type}")
        print(f"vn_kv/pn_bar: {getattr(self, 'vn_kv', getattr(self, 'pn_bar', 'None'))}")

        self.current_crs = int(network_data['current_crs']) if network_data['current_crs'] else 4326
        self.crs = self.sourceCrs()
        self.fields_list = None
        self.df = None
        self._extent = None

        provider_list = QgsProviderRegistry.instance().providerList()
        print("provider list by init ppprovider", provider_list)
        self._is_valid = True

        # State tracking variables for asynchronous save operation of the changeGeometryValues method
        self._save_in_progress = False  # Indicates whether a save operation is in progress
        self._save_thread = None  # QThread instance performing the save operation

        # print("")
        # print("")
        #
        # print("=" * 50)
        # print("pandapower_provider.py, init method")
        # # Bring network data from container
        # print(f"[DEBUG] Getting network data from container with URI: {uri}")
        # #network_data = NetworkContainer.get_network(uri)
        #
        # if network_data is None:
        #     print(f"[DEBUG] Failed to get network data from container")
        #     self._is_valid = False
        #     print("Warning: Failed to load Network data from Network container.\n")
        #     return
        # else:
        #     print(f"[DEBUG] Successfully got network data from container")
        #     print(f"[DEBUG] Network data keys: {list(network_data.keys())}")
        #
        # # Setting network data
        # self.net = network_data['net']
        # print(f"[DEBUG] Network object type: {type(self.net)}")
        # print(
        #     f"[DEBUG] Network object keys: {list(self.net.keys()) if hasattr(self.net, 'keys') else 'No keys method'}")
        # print("=" * 50)

        # ğŸŒŸ ìƒˆë¡œìš´ ê¸°ëŠ¥: NetworkContainerì— "ë‚˜ ì•Œë¦¼ ë°›ì„ë˜!" ë“±ë¡
        NetworkContainer.add_listener(self.uri, self)
        print(f"ğŸ“¢ Provider {self.uri}: NetworkContainerì— ì•Œë¦¼ ë“±ë¡ ì™„ë£Œ")
        print(f"ğŸ“‹ í˜„ì¬ ë“±ë¡ëœ ë¦¬ìŠ¤ë„ˆë“¤: {NetworkContainer._listeners}")
        print(f"ğŸ“‹ ë‚´ê°€ ë“±ë¡ëë‚˜?: {self in NetworkContainer._listeners.get(self.uri, [])}")
        print("=" * 50)

    # ì›ë³¸
    def merge_df(self):
        """
        Merges the network type dataframe with its corresponding result dataframe.
        Only includes data with matching vn_kv value.
        """
        print("=" * 50)
        print("=" * 50)
        print("\n\nnow in merge_df\n\n")

        try:
            # Get the dataframes for the network type and its result
            df_network_type = getattr(self.net, self.network_type)
            df_res_network_type = getattr(self.net, f'res_{self.network_type}')

            # df_network_typeì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
            print(f"Index of df_{self.network_type}:")
            print(df_network_type.index) # Debugging
            # df_res_network_typeì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
            print(f"Index of df_res_{self.network_type}:")
            print(df_res_network_type.index)

            if df_network_type is None:
                print(f"Error: No dataframe found for {self.network_type}.")
                self.df = pd.DataFrame()  # Set to empty DataFrame
                return

            print(f"Before sorting df_{self.network_type}\n", df_network_type.head())
            print(f"Before sorting df_res_{self.network_type}\n", df_res_network_type.head())
            print(f"Original df_{self.network_type} shape: {df_network_type.shape}")
            if df_res_network_type is not None:
                print(f"Original df_res_{self.network_type} shape: {df_res_network_type.shape}")

            # ğŸ” í•µì‹¬: ì–´ë–¤ ìƒí™©ì¸ì§€ íŒë‹¨í•˜ê¸°
            has_result_data = (df_res_network_type is not None and
                               not df_res_network_type.empty and
                               len(df_res_network_type) > 0)

            # when res column not empty
            if has_result_data:
                print("âœ… ê³„ì‚° ê²°ê³¼ê°€ ìˆì–´ìš”! ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
                # Filter vn_kv before sort
                if self.vn_kv is not None:
                    # If line, pipe: merge all
                    if self.network_type == 'bus':
                        filtered_indices = df_network_type[df_network_type['vn_kv'] == self.vn_kv].index
                        df_network_type = df_network_type.loc[filtered_indices]
                        if df_res_network_type is not None:
                            df_res_network_type = df_res_network_type.loc[filtered_indices]
                    elif self.network_type == 'junction':   # pn_bar
                        if 'vn_kv' in df_network_type.columns:
                            filtered_indices = df_network_type[df_network_type['vn_kv'] == self.vn_kv].index
                            df_network_type = df_network_type.loc[filtered_indices]
                            if df_res_network_type is not None:
                                df_res_network_type = df_res_network_type.loc[filtered_indices]
                    print(f"After filtering with vn_kv={self.vn_kv}, df_{self.network_type} shape: {df_network_type.shape}")

                # Sort indices
                df_network_type.sort_index(inplace=True)
                if df_res_network_type is not None:
                    df_res_network_type.sort_index(inplace=True)

                print(f"After sorting df_{self.network_type}\n", df_network_type.head())
                print(f"After sorting df_res_{self.network_type}\n", df_res_network_type.head())

                # Check if the result dataframe exists
                if df_res_network_type is not None:
                    # Merge the two dataframes on their indices
                    self.df = pd.merge(df_network_type, df_res_network_type, left_index=True, right_index=True, suffixes=('', '_res'))
                    print("Merged DataFrame (1):") # Debugging
                    print(self.df.head())
                else:
                    # If the result dataframe does not exist, use only the network type dataframe
                    self.df = df_network_type
                    print(f"Warning: No res_{self.network_type} exist. Only {self.network_type} returned.")

            # when res column of json file is cleared
            elif not has_result_data:
                print("âš ï¸ ê³„ì‚° ê²°ê³¼ê°€ ì—†ì–´ìš”! ìƒˆë¡œìš´ ë°©ì‹ ì‚¬ìš©")

                # ğŸ¯ í•µì‹¬: ê¸°ë³¸ ë°ì´í„°ì— ë¹ˆ ê²°ê³¼ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                self.df = df_network_type.copy()  # ê¸°ë³¸ ë°ì´í„° ë³µì‚¬

                # ğŸ”§ ë¹ˆ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                res_columns = df_res_network_type.columns.tolist()
                for col_name in res_columns:
                    self.df[col_name] = None  # ë˜ëŠ” ì ì ˆí•œ ê¸°ë³¸ê°’

                print(f"âœ… {len(res_columns)}ê°œì˜ ë¹ˆ ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ!")

            # Check if the merged dataframe is empty
            if self.df.empty:
                print(f"Warning: Merged dataframe for {self.network_type} is empty.")

            # Create 'pp_type' and 'pp_index' columns
            self.df.insert(0, 'pp_type', self.network_type)
            self.df.insert(1, 'pp_index', self.df.index)
            # Convert pandas index to string
            #self.df.insert(1, 'pp_index', self.df.index.astype(str).tolist())

            print("Merged DataFrame (2):")  # Debugging
            print(self.df.head())
            print("="*50)
            print("=" * 50)

        except Exception as e:
            print(f"Error merging dataframes for {self.network_type}: {str(e)}")
            print("=" * 50)
            print("=" * 50)
            return pd.DataFrame()  # Return an empty DataFrame in case of error

    # 1ì°¨ ìˆ˜ì •ë³¸ - í•µì‹¬ ìˆ˜ì •: vn_kv í•„í„°ë§ì„ ê³µí†µìœ¼ë¡œ ë¨¼ì € ì ìš©
    # ì™œ ì£¼ì„ì²˜ë¦¬ëëŠ”ì§€ ì•Œì•„ë³´ê¸°
    # def merge_df(self):
    #     """
    #     Merges the network type dataframe with its corresponding result dataframe.
    #     Only includes data with matching vn_kv value.
    #     """
    #     print("=" * 50)
    #     print("=" * 50)
    #     print("\n\nnow in merge_df\n\n")
    #
    #     try:
    #         # Get the dataframes for the network type and its result
    #         df_network_type = getattr(self.net, self.network_type)
    #         df_res_network_type = getattr(self.net, f'res_{self.network_type}')
    #
    #         # df_network_typeì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    #         print(f"Index of df_{self.network_type}:")
    #         print(df_network_type.index)  # Debugging
    #         # df_res_network_typeì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    #         print(f"Index of df_res_{self.network_type}:")
    #         print(df_res_network_type.index)
    #
    #         if df_network_type is None:
    #             print(f"Error: No dataframe found for {self.network_type}.")
    #             self.df = pd.DataFrame()  # Set to empty DataFrame
    #             return
    #
    #         print(f"Before sorting df_{self.network_type}\n", df_network_type.head())
    #         print(f"Before sorting df_res_{self.network_type}\n", df_res_network_type.head())
    #         print(f"Original df_{self.network_type} shape: {df_network_type.shape}")
    #         if df_res_network_type is not None:
    #             print(f"Original df_res_{self.network_type} shape: {df_res_network_type.shape}")
    #
    #         # ğŸ” í•µì‹¬: ì–´ë–¤ ìƒí™©ì¸ì§€ íŒë‹¨í•˜ê¸°
    #         has_result_data = (df_res_network_type is not None and
    #                            not df_res_network_type.empty and
    #                            len(df_res_network_type) > 0)
    #
    #         # ğŸ¯ í•µì‹¬ ìˆ˜ì •: vn_kv í•„í„°ë§ì„ ê³µí†µìœ¼ë¡œ ë¨¼ì € ì ìš©
    #         # Filter vn_kv BEFORE checking result data
    #         original_df_network_type = df_network_type.copy()  # ì›ë³¸ ë°±ì—…
    #
    #         if hasattr(self, 'vn_kv') and self.vn_kv is not None:
    #             print(f"ğŸ” vn_kv í•„í„°ë§ ì ìš©: {self.vn_kv}")
    #
    #             if self.network_type == 'bus':
    #                 # ë²„ìŠ¤ì˜ ê²½ìš° vn_kvë¡œ í•„í„°ë§
    #                 filtered_indices = df_network_type[df_network_type['vn_kv'] == self.vn_kv].index
    #                 df_network_type = df_network_type.loc[filtered_indices]
    #                 print(f"ğŸ” ë²„ìŠ¤ í•„í„°ë§ í›„ shape: {df_network_type.shape}")
    #
    #                 # ê²°ê³¼ ë°ì´í„°ë„ ê°™ì€ ì¸ë±ìŠ¤ë¡œ í•„í„°ë§
    #                 if df_res_network_type is not None and not df_res_network_type.empty:
    #                     df_res_network_type = df_res_network_type.loc[
    #                         df_res_network_type.index.intersection(filtered_indices)
    #                     ]
    #                     print(f"ğŸ” ê²°ê³¼ ë°ì´í„° í•„í„°ë§ í›„ shape: {df_res_network_type.shape}")
    #
    #             elif self.network_type == 'junction':  # pn_barì˜ ê²½ìš°
    #                 if hasattr(self, 'pn_bar') and self.pn_bar is not None:
    #                     if 'pn_bar' in df_network_type.columns:
    #                         filtered_indices = df_network_type[df_network_type['pn_bar'] == self.pn_bar].index
    #                         df_network_type = df_network_type.loc[filtered_indices]
    #
    #                         if df_res_network_type is not None and not df_res_network_type.empty:
    #                             df_res_network_type = df_res_network_type.loc[
    #                                 df_res_network_type.index.intersection(filtered_indices)
    #                             ]
    #
    #             # lineê³¼ pipeëŠ” from_bus/to_busë¥¼ í†µí•´ ì—°ê²°ëœ ê²ƒë“¤ë§Œ í¬í•¨
    #             elif self.network_type in ['line', 'pipe']:
    #                 # ì´ë¯¸ ppqgis_import.pyì—ì„œ í•„í„°ë§ëœ ìƒíƒœë¡œ ì „ë‹¬ë¨
    #                 pass
    #
    #         # í•„í„°ë§ í›„ ìƒíƒœ í™•ì¸
    #         has_result_data = (df_res_network_type is not None and
    #                            not df_res_network_type.empty and
    #                            len(df_res_network_type) > 0)
    #
    #         # when res column not empty
    #         if has_result_data:
    #             print("âœ… ê³„ì‚° ê²°ê³¼ê°€ ìˆì–´ìš”! ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
    #
    #             # Sort indices
    #             df_network_type.sort_index(inplace=True)
    #             df_res_network_type.sort_index(inplace=True)
    #
    #             print(f"After sorting df_{self.network_type}\n", df_network_type.head())
    #             print(f"After sorting df_res_{self.network_type}\n", df_res_network_type.head())
    #
    #             # Merge the two dataframes on their indices
    #             self.df = pd.merge(df_network_type, df_res_network_type, left_index=True, right_index=True,
    #                                suffixes=('', '_res'))
    #             print("Merged DataFrame (1):")  # Debugging
    #             print(self.df.head())
    #
    #         # when res column of json file is cleared
    #         elif not has_result_data:
    #             print("âš ï¸ ê³„ì‚° ê²°ê³¼ê°€ ì—†ì–´ìš”! ìƒˆë¡œìš´ ë°©ì‹ ì‚¬ìš©")
    #
    #             # ğŸ¯ í•µì‹¬: ì´ë¯¸ í•„í„°ë§ëœ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©
    #             self.df = df_network_type.copy()  # í•„í„°ë§ëœ ë°ì´í„° ë³µì‚¬
    #             print(f"âœ… í•„í„°ë§ëœ ê¸°ë³¸ ë°ì´í„° shape: {self.df.shape}")
    #
    #             # ğŸ”§ ë¹ˆ ê²°ê³¼ ì»¬ëŸ¼ë“¤ ì¶”ê°€ (ì›ë³¸ res ì»¬ëŸ¼ êµ¬ì¡° ì°¸ê³ )
    #             # ì›ë³¸ì—ì„œ res ì»¬ëŸ¼ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°
    #             original_res = getattr(self.net, f'res_{self.network_type}')
    #             if original_res is not None and not original_res.empty:
    #                 res_columns = original_res.columns.tolist()
    #                 for col_name in res_columns:
    #                     self.df[col_name] = None  # ë˜ëŠ” ì ì ˆí•œ ê¸°ë³¸ê°’
    #                 print(f"âœ… {len(res_columns)}ê°œì˜ ë¹ˆ ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ!")
    #             else:
    #                 print("âš ï¸ ì›ë³¸ ê²°ê³¼ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    #
    #         # Check if the merged dataframe is empty
    #         if self.df.empty:
    #             print(f"Warning: Merged dataframe for {self.network_type} is empty.")
    #
    #         # Create 'pp_type' and 'pp_index' columns
    #         self.df.insert(0, 'pp_type', self.network_type)
    #         self.df.insert(1, 'pp_index', self.df.index)
    #
    #         print("Final DataFrame:")  # Debugging
    #         print(f"Shape: {self.df.shape}")
    #         print(f"Columns: {list(self.df.columns)}")
    #         print(self.df.head())
    #         print("=" * 50)
    #         print("=" * 50)
    #
    #     except Exception as e:
    #         print(f"Error merging dataframes for {self.network_type}: {str(e)}")
    #         print("=" * 50)
    #         print("=" * 50)
    #         return pd.DataFrame()  # Return an empty DataFrame in case of error



    def fields(self) -> QgsFields:
        """
        í…Œì´ë¸”ì˜ í•„ë“œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì§€ì—° ì´ˆê¸°í™”(lazy initialization) íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œë¡œ í•„ìš”í•  ë•Œë§Œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        Return field data of table.
        Using lazy initialization pattern, search database only when it needed.
        """
        #if not self.fields_list:  # ì²« í˜¸ì¶œ ì‹œì—ë§Œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤
        #print("length of self.fields_list: ", len(self.fields_list))
        #if len(self.fields_list) == 0:  # ì²« í˜¸ì¶œ ì‹œì—ë§Œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤
        if not self.fields_list:
            self.fields_list = QgsFields()

            print("length is 0, called merge df")
            self.merge_df()

            # Check if dataframe is empty
            if self.df.empty:
                print(f"No data available for network type: {self.network_type}, called in fields method while initializing")  # Debugging
                return
            else:
                print("print df.columns: ", self.df.columns)
                # print(f"Dataframe for {self.type_layer_name} has {len(df)} rows.")

            # generate fields_list dynamically from column of the dataframe
            for column in self.df.columns:
                dt = self.df[column].dtype
                qm = convert_dtype_to_qmetatype(dt)
                self.fields_list.append(QgsField(column, qm))
                # print(f"Generate field: {column} with type {qm}")  # Debugging

            # Determine geometry type based on network type
            geometry_type = "Point" if self.network_type in ['bus', 'junction'] else "LineString"
            print(f"Geometry type for {self.network_type}: {geometry_type}")  # Debugging
            print(f"URI type: {type(self.uri)}, value: {self.uri}")  # Debugging

            '''
            for field in self.fields_list:
                if not self.layer.addAttribute(field):
                    raise RuntimeError(f"Failed to add attribute: {field.name()}")
                # print(f"Added attribute fields to layer: {field.name()}")  # Debugging

            self.populate_features()
            '''

        return self.fields_list


    def getFeatures(self, request=QgsFeatureRequest()):
        """Return next feature"""
        return QgsFeatureIterator(
            pandapower_feature_iterator.PandapowerFeatureIterator(
                pandapower_feature_source.PandapowerFeatureSource(self), request
            )
        )


    def changeGeometryValues(self, geometry_map):
        """
        Changes geometries of existing features.

        :param geometry_map: A QgsGeometryMap whose index contains the feature IDs
            that will have their geometries changed.
            The second map parameter being the new geometries themselves.
        :type geometry_map: typedef QMap<QgsFeatureId, QgsGeometry> QgsGeometryMap
        :return: True if geometries were changed successfully, False otherwise.
        :rtype: bool
        """
        print("\nchangeGeometryValues")
        print(f"Feature IDs in geometry_map: {list(geometry_map.keys())}")
        print(f"Dataframe indices: {list(self.df.index)}")
        #print(f"Geodata indices: {list(getattr(self.net, f'{self.network_type}_geodata').index)}\n")
        print(f"Geodata indices: {list(getattr(self.net, f'{self.network_type}').geo.index)}\n")

        # Check if an existing save operation is in progress
        if self._save_in_progress:
            from qgis.utils import iface
            from qgis.core import Qgis
            iface.messageBar().pushMessage(
                "Notification",
                "The previous save operation is still in progress. Please try again after it is completed.",
                level=Qgis.Warning,
                duration=5
            )
            return False  # Operation denied

        # Proceed to update and save the dataframe only when a save operation is not in progress
        try:
            # Update Geodata of Pandapower Network
            for feature_id, new_geometry in geometry_map.items():
                if self.network_type in ['bus', 'junction']:
                    # If bus or junction, update x, y geometry
                    x = new_geometry.asPoint().x()
                    y = new_geometry.asPoint().y()

                    # Update geodata of dataframe
                    geodata_df = getattr(self.net, f'{self.network_type}').geo
                    if feature_id in geodata_df.index:
                        #geodata_df.at[feature_id, 'x'] = x
                        #geodata_df.at[feature_id, 'y'] = y
                        try:
                            # Load geo data of existing dataframe and convert it into python dict
                            geo_str = geodata_df.loc[feature_id]
                            geo_data = json.loads(geo_str)

                            # Update coordinates in 'coordinates' key of the dictionary
                            geo_data['coordinates'] = [x, y]

                            # Convert back into json String and save updated data in dataframe
                            geodata_df.loc[feature_id] = json.dumps(geo_data)
                            print(f"Updated {self.network_type} geometry at ID {feature_id}: ({x}, {y})")
                        except Exception as e:
                            print(f"Error updating geometry for ID {feature_id}: {str(e)}")
                    else:
                        print(f"Warning: {self.network_type} with ID {feature_id} not found in geodata")

                elif self.network_type in ['line', 'pipe']:
                    # If line or pipe, update coord list
                    points = new_geometry.asPolyline()
                    coords = [(point.x(), point.y()) for point in points]

                    # Update geodata of dataframe
                    #geodata_df = getattr(self.net, f'{self.network_type}_geodata')
                    geodata_df = getattr(self.net, f'{self.network_type}').geo
                    if feature_id in geodata_df.index:
                        #geodata_df.at[feature_id, 'coords'] = coords
                        try:
                            # Load geo data of existing dataframe and convert it into python dict
                            geo_str = geodata_df.loc[feature_id]
                            geo_data = json.loads(geo_str)

                            # Update coordinates in 'coordinates' key of the dictionary
                            geo_data['coordinates'] = coords

                            # Convert back into json String and save updated data in dataframe
                            geodata_df.loc[feature_id] = json.dumps(geo_data)
                            print(f"Updated {self.network_type} geometry at ID {feature_id} with {len(coords)} points")
                        except Exception as e:
                            print(f"Error updating line geometry for ID {feature_id}: {str(e)}")
                    else:
                        print(f"Warning: {self.network_type} with ID {feature_id} not found in geodata")

            '''
            # Synchronous file saving tasks
            try:
                # ë³€ê²½ëœ ì¢Œí‘œë¥¼ ì›ë³¸ íŒŒì¼ì— ë°˜ì˜ # ë©”ì„œë“œ ë§ˆì§€ë§‰ì— ë ˆì´ì–´ ë‹¤ì‹œ ê·¸ë¦° ë‹¤ìŒì— í•˜ëŠ” ê²Œ ë§ì•„ë³´ì´ëŠ”ë° ì¼ë‹¨ ê³ 
                # íˆ¬ë‘: ìˆ˜ë™ ì €ì¥ ì˜µì…˜
                if self.update_geodata_in_json():
                    print(f"ì¢Œí‘œ ë³€ê²½ ì‚¬í•­ì´ '{self.uri_parts.get('path', '')}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
            except Exception as e:
                print(f"Failed to save changed geo data: {str(e)}")
                raise
            
            # ë³€ê²½ ì‚¬í•­ ì•Œë¦¼ì„ ë³´ë‚´ê¸° ìœ„í•œ signal ë°œìƒ
            # ì´ëŠ” QGISê°€ ë°ì´í„° ë³€ê²½ì„ ì¸ì‹í•˜ê³  í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë¦¬ë„ë¡ í•˜ëŠ” ì¤‘ìš”í•œ ë‹¨ê³„
            self.dataChanged.emit()
            # ìºì‹œ ë¬´íš¨í™” ì‹œë„ (ì´ ë©”ì„œë“œê°€ ìˆë‹¤ë©´)
            if hasattr(self, 'cacheInvalidate'):
                self.cacheInvalidate()
            # ë ˆì´ì–´ ëª…ì‹œì  ê°±ì‹  ì‹œë„
            try:
                # ë ˆì´ì–´ ê°ì²´ ì°¾ê¸°
                layers = QgsProject.instance().mapLayersByName(self.type_layer_name)
                if layers:
                    # ëª…ì‹œì  ë¦¬í˜ì¸íŠ¸ íŠ¸ë¦¬ê±°
                    layers[0].triggerRepaint()
                    print(f"Triggered repaint for layer: {self.type_layer_name}")
            except Exception as e:
                print(f"Warning: Could not trigger layer repaint: {str(e)}")
            return True
            '''

            # Asynchronous file saving tasks
            # Define a callback function to be executed after saving
            def on_save_complete(success, message, backup_path=None):
                self._save_in_progress = False

                # UI Feedback for success or failure
                from qgis.core import Qgis
                from qgis.utils import iface

                if success:
                    # Display success message in UI
                    iface.messageBar().pushMessage(
                        "Saved Successfully",
                        message,
                        level=Qgis.Success,
                        duration=5
                    )

                    # Display backup file information
                    if backup_path:
                        iface.messageBar().pushMessage(
                            "Backup file created",
                            f"path: {backup_path}",
                            level=Qgis.Info,
                            duration=8
                        )

                    # Change Notification Triggered
                    self.dataChanged.emit()

                    # ìºì‹œ ë¬´íš¨í™” (ì´ ë©”ì„œë“œê°€ ìˆë‹¤ë©´)
                    #if hasattr(self, 'cacheInvalidate'):
                        #self.cacheInvalidate()

                    # Explicit Layer Update
                    # Maybe not necessary
                    try:
                        layers = QgsProject.instance().mapLayersByName(self.type_layer_name)
                        if layers:
                            layers[0].triggerRepaint()
                            print(f"Triggered repaint for layer: {self.type_layer_name}")
                    except Exception as e:
                        print(f"Warning: Could not trigger layer repaint: {str(e)}")
                else:
                    # Display failure message to UI
                    iface.messageBar().pushMessage(
                        "Save failed",
                        message,
                        level=Qgis.Critical,
                        duration=10
                    )

            # Start asynchronous save
            self.update_geodata_in_json_async(on_save_complete)
            # Notify that the save operation has started
            return True

        except Exception as e:
            self.pushError(f"Failed to change geometries: {str(e)}")
            import traceback
            traceback.print_exc()
            return False




    # def on_update_changed_network(self, network_data):
    #     """
    #     âœ… ìµœì¢… ì•ˆì •í™”ëœ ë²„ì „ - ë””ë²„ê¹… ì½”ë“œ ì œê±°
    #     NetworkContainerë¡œë¶€í„° "ë°ì´í„° ë°”ë€Œì—ˆì–´!" ì•Œë¦¼ì„ ë°›ëŠ” ë©”ì„œë“œ
    #     """
    #     try:
    #         # 1ï¸âƒ£ ë„¤íŠ¸ì›Œí¬ ê°ì²´ ì—…ë°ì´íŠ¸
    #         self.net = network_data['net']
    #
    #         ì—¬ê¸°ì„œ ê·¸ëƒ¥ self.net ë°ì´í„° ê·¸ëŒ€ë¡œ ë°›ìœ¼ë©´ ì•ˆë¨? ì›¨ì•ˆë˜ê²Œ í•´ë†§ì§€?
    #         # 2ï¸âƒ£ ë°ì´í„°í”„ë ˆì„ ì¬ìƒì„± (ê²°ê³¼ ì»¬ëŸ¼ í¬í•¨)
    #         self.fields_list = None  # í•„ë“œ ìºì‹œ ì´ˆê¸°í™”
    #         self.df = None  # ë°ì´í„°í”„ë ˆì„ ìºì‹œ ì´ˆê¸°í™”
    #
    #         # 3ï¸âƒ£ QGISì—ê²Œ ë°ì´í„° ë³€ê²½ ì•Œë¦¼
    #         self.dataChanged.emit()
    #
    #         print(f"âœ… Provider {self.uri}: ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    #
    #     except Exception as e:
    #         print(f"âŒ Provider {self.uri}: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - {str(e)}")
    #         # ê°œë³„ Provider ì‹¤íŒ¨ëŠ” ì „ì²´ ì‹œìŠ¤í…œì„ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ


    #0708 ìƒˆë²½ì— ë””ë²„ê¹…í•˜ê¸° ìœ„í•´ ì£¼ì„ì²˜ë¦¬ì¤‘
    def on_update_changed_network(self, network_data):
        """
        ğŸ›¡ï¸ ìµœì¢… ì•ˆì „í™”ëœ ë°ì´í„° ì—…ë°ì´íŠ¸ - Race Condition ë°©ì§€
        """
        print("\n")
        print("="*50)
        print(f"ğŸšš ì—¬ê¸°ëŠ” on_update_changed_network: ë„¤íŠ¸ì›Œí¬ ì»¨í…Œì´ë„ˆì—ì„œ {self.uri} ë°°ë‹¬ ë°›ìŒ!")  # â† ì´ê±° ì¶”ê°€
        print(f"ğŸ”” {self.uri}: ì•Œë¦¼ ë°›ìŒ!")
        print(f"ğŸ”” ì´ì „ ë°ì´í„° í¬ê¸°: {len(self.df) if self.df is not None else 0}")

        old_net = self.net
        try:
            print(f"ğŸ“¨ Provider {self.uri}: ì•ˆì „í•œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘")

            # ğŸ”’ 1ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ ê°ì²´ ì—…ë°ì´íŠ¸ (ì•ˆì „)
            self.net = network_data['net']

            # ğŸ”’ 2ë‹¨ê³„: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ë³„ë„ ë³€ìˆ˜ì—ì„œ ìƒì„± (Race Condition ë°©ì§€)
            new_df = self._create_updated_dataframe()
            if new_df is None:  # â† ì´ ê²½ìš° ë Œë”ëŸ¬ê°€ ë¹ˆ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ
                print("âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸ DataFrame ìƒì„± ì‹¤íŒ¨! âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸âš ï¸")

            # ğŸ”’ 3ë‹¨ê³„: ê²€ì¦ í›„ í•œ ë²ˆì— êµì²´ (Atomic Operation)
            if new_df is not None and not new_df.empty:
                # ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°ì—ë§Œ êµì²´
                #self.fields_list = None  # í•„ë“œ ìºì‹œ ì´ˆê¸°í™”
                self.df = new_df  # ìƒˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµì²´

                # # ğŸ”’ 4ë‹¨ê³„: QGIS ì•Œë¦¼ (ë°ì´í„°ê°€ ì¤€ë¹„ëœ í›„)
                # print(f"ğŸ”” ìƒˆ ë°ì´í„° í¬ê¸°: {len(new_df) if new_df is not None else 0}")
                # self.dataChanged.emit()
                # print(f"ğŸ”” dataChanged ì‹ í˜¸ ë°œìƒ!")
                # print(f"âœ… Provider {self.uri}: ì•ˆì „í•œ ì—…ë°ì´íŠ¸ ì™„ë£Œ (í¬ê¸°: {len(new_df)})")
            else:
                # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ì¡´ ë°ì´í„° ìœ ì§€
                print(f"âš ï¸ Provider {self.uri}: ìƒˆ ë°ì´í„° ìƒì„± ì‹¤íŒ¨, ê¸°ì¡´ ë°ì´í„° ìœ ì§€")

        except Exception as e:
            print(f"âŒ Provider {self.uri}: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ìƒíƒœ ë³µì› ì‹œë„
            if 'old_net' in locals():
                self.net = old_net

    def _create_updated_dataframe(self):
        """
        ğŸ”§ ë³„ë„ í•¨ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ìƒˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        ê¸°ì¡´ merge_df() ë¡œì§ì„ ë³µì‚¬í•˜ë˜, self.dfë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
        """
        try:
            # ê¸°ì¡´ merge_df ë¡œì§ì„ ìƒˆ ë³€ìˆ˜ì—ì„œ ì‹¤í–‰
            df_network_type = getattr(self.net, self.network_type)
            df_res_network_type = getattr(self.net, f'res_{self.network_type}')

            if df_network_type is None:
                print(f"âš ï¸ {self.network_type} ë°ì´í„°ê°€ ì—†ìŒ")
                return None

            # ê³„ì‚° ê²°ê³¼ í™•ì¸
            has_result_data = (df_res_network_type is not None and
                               not df_res_network_type.empty and
                               len(df_res_network_type) > 0)

            if has_result_data:
                print("âœ… ê³„ì‚° ê²°ê³¼ê°€ ìˆì–´ìš”! ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")

                # vn_kv í•„í„°ë§ (ê¸°ì¡´ ë¡œì§)
                if hasattr(self, 'vn_kv') and self.vn_kv is not None:
                    if self.network_type == 'bus':
                        filtered_indices = df_network_type[df_network_type['vn_kv'] == self.vn_kv].index
                        df_network_type = df_network_type.loc[filtered_indices]
                        df_res_network_type = df_res_network_type.loc[filtered_indices]

                # ì •ë ¬
                df_network_type.sort_index(inplace=True)
                df_res_network_type.sort_index(inplace=True)

                # ë³‘í•©
                new_df = pd.merge(df_network_type, df_res_network_type,
                                  left_index=True, right_index=True, suffixes=('', '_res'))
            else:
                print("âš ï¸ ê³„ì‚° ê²°ê³¼ê°€ ì—†ì–´ìš”! ìƒˆë¡œìš´ ë°©ì‹ ì‚¬ìš©")
                new_df = df_network_type.copy()

                # ë¹ˆ ê²°ê³¼ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                if df_res_network_type is not None:
                    res_columns = df_res_network_type.columns.tolist()
                    for col_name in res_columns:
                        new_df[col_name] = None

            # pp_typeê³¼ pp_index ì»¬ëŸ¼ ì¶”ê°€
            new_df.insert(0, 'pp_type', self.network_type)
            new_df.insert(1, 'pp_index', new_df.index)

            print(f"âœ… ìƒˆ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ: {len(new_df)}í–‰")
            return new_df

        except Exception as e:
            print(f"âŒ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None



    def update_geodata_in_json_async(self, callback=None):
        """
        Asynchronously updates the changed geodata in the original JSON file.
        Note: It is method for asynchronous update. For synchronous update, see update_geodata_in_json()

        :param callback: Function to be called after saving is complete.
                        on_save_complete(success, message, backup_path)
        """
        # Do not process new requests if a save operation is already in progress
        if self._save_in_progress:
            from qgis.utils import iface
            from qgis.core import Qgis
            iface.messageBar().pushMessage(
                "Notify",
                "A save operation is already in progress. Please try again later.",
                level=Qgis.Info
            )
            return
        else:
            self._save_in_progress = True

        from PyQt5.QtCore import QThread, pyqtSignal

        class SaveThread(QThread):
            # Save Completion Signal (Success Status, Message, Backup Path)
            saveCompleted = pyqtSignal(bool, str, str)

            def __init__(self, provider):
                super().__init__()
                self.provider = provider

            def run(self):
                try:
                    import pandapower as pp
                    import os
                    import shutil
                    from datetime import datetime

                    original_path = self.provider.uri_parts.get('path', '')
                    if not original_path or not os.path.exists(original_path):
                        self.saveCompleted.emit(False, f"Cannot find original file at: {original_path}", "")
                        return

                    # Create Backup File (Add Date/Time Stamp)
                    backup_path = f"{original_path}.{datetime.now().strftime('%Y%m%d_%H%M%S')}.bak"
                    try:
                        shutil.copy2(original_path, backup_path)
                        print(f"The backup file has been created: {backup_path}")
                    except Exception as e:
                        print(f"An error occurred while creating the backup file: {str(e)}")
                        # ë°±ì—… ìƒì„± ì‹¤íŒ¨ê°€ ì‹¬ê°í•œ ë¬¸ì œëŠ” ì•„ë‹ˆë¼ê³  ê°„ì£¼í•˜ê³  ê³„ì† ì§„í–‰í•˜ë ¤ë©´
                        #backup_path = ""
                        return

                    # Load original network from json file
                    try:
                        original_net = pp.from_json(original_path)
                    except Exception as e:
                        self.saveCompleted.emit(False, f"Fail to load original network: {str(e)}", backup_path)
                        return

                    # í˜„ì¬ ë©”ëª¨ë¦¬ì˜ ë³€ê²½ëœ geodata
                    current_geodata = getattr(self.provider.net, f"{self.provider.network_type}").geo

                    # ì›ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ geodataë¥¼ ë³€ê²½ëœ ì¢Œí‘œë¡œ ì—…ë°ì´íŠ¸
                    # í•„í„°ë§ëœ ë°ì´í„°ë§Œ ê³ ë ¤ë¨
                    original_geodata = getattr(original_net, f"{self.provider.network_type}").geo

                    for idx in current_geodata.index:
                        if idx in original_geodata.index:
                            # í˜„ì¬ JSON ë¬¸ìì—´ì„ ì›ë³¸ì— ë³µì‚¬
                            original_geodata.loc[idx] = current_geodata.loc[idx]

                    # ì—…ë°ì´íŠ¸ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ jsonìœ¼ë¡œ ì €ì¥
                    try:
                        pp.to_json(original_net, original_path)
                        success_msg = f"ì¢Œí‘œ ë³€ê²½ ì‚¬í•­ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {original_path}"
                        self.saveCompleted.emit(True, success_msg, backup_path)
                    except PermissionError:
                        error_msg = f"íŒŒì¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì—´ë ¤ìˆê±°ë‚˜ ì“°ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {original_path}"
                        self.saveCompleted.emit(False, error_msg, backup_path)
                    except Exception as e:
                        error_msg = f"An error occurred while saving file: {str(e)}"
                        self.saveCompleted.emit(False, error_msg, backup_path)

                except Exception as e:
                    import traceback
                    error_msg = f"An error occurred while updating geodata: {str(e)}"
                    traceback.print_exc()
                    self.saveCompleted.emit(False, error_msg, "")

        # Create a thread for saving
        self._save_thread = SaveThread(self)

        # Connect callback
        if callback:
            self._save_thread.saveCompleted.connect(callback)

        # Starting thread
        self._save_thread.start()


    def update_geodata_in_json(self, auto_save=True):
        """
        Update changed geodata of original json file with pandapower API.
        If auto_save False, changed geodata kept in memory only.
        Currently support auto save only.
        Note: It is method for synchronous update. For asynchronous update, see update_geodata_in_json_async()
        """
        if not auto_save:
            print("Keep changes in memory without saving.")
            return True

        try:
            import pandapower as pp
            import os
            import shutil
            from datetime import datetime

            original_path = self.uri_parts.get('path', '')
            if not original_path or not os.path.exists(original_path):
                self.pushError(f"The original file cannot be found at: {original_path}")
                return False

            # Create backup of json file before editing (add Date/Time stamp)
            backup_path = f"{original_path}.{datetime.now().strftime('%Y%m%d_%H%M%S')}.bak"
            try:
                shutil.copy2(original_path, backup_path)
                print(f"A backup file has been created: {backup_path}")
            except Exception as e:
                print(f"An error occurred while creating backup file: {str(e)}")
                # continue

            # Load original network from json
            original_net = pp.from_json(original_path)

            # Changed geodata of current memory
            #current_geodata = getattr(self.net, f"{self.network_type}_geodata")
            current_geodata = getattr(self.net, f"{self.network_type}").geo

            # Update geodata of original network as changed coordinate
            # Only filtered data considered
            #original_geodata = getattr(original_net, f"{self.network_type}_geodata")
            original_geodata = getattr(original_net, f"{self.network_type}").geo

            for idx in current_geodata.index:
                if idx in original_geodata.index:
                    '''
                    if self.network_type in ['bus', 'junction']:
                        if 'x' in current_geodata.columns and 'y' in current_geodata.columns:
                            original_geodata.at[idx, 'x'] = current_geodata.at[idx, 'x']
                            original_geodata.at[idx, 'y'] = current_geodata.at[idx, 'y']
                    elif self.network_type in ['line', 'pipe']:
                        if 'coords' in current_geodata.columns:
                            original_geodata.at[idx, 'coords'] = current_geodata.at[idx, 'coords']
                    '''
                    # Copy current geodata (json String) to the original network
                    original_geodata.loc[idx] = current_geodata.loc[idx]

            # Save updated network to json
            try:
                pp.to_json(original_net, original_path)
                print(f"Changed coordinates of {original_path} is successfully saved.")
                return True
            except PermissionError:
                self.pushError(f"Cannot reach to {original_path}. The file may opened in another program or required permissions.")
                return False
            except Exception as e:
                self.pushError(f"An Error occurred while saving: {str(e)}")
                return False

        except Exception as e:
            self.pushError(f"Error occurred while updating geodata: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


    def capabilities(self) -> QgsVectorDataProvider.Capabilities:
        return (
            QgsVectorDataProvider.CreateSpatialIndex |
            QgsVectorDataProvider.SelectAtId |
            QgsVectorDataProvider.ChangeGeometries
        )

    def crs(self) -> QgsCoordinateReferenceSystem:
        return self.sourceCrs()

    def sourceCrs(self) -> QgsCoordinateReferenceSystem:
        crs = QgsCoordinateReferenceSystem.fromEpsgId(int(self.current_crs))
        if not crs.isValid():
            raise ValueError(f"CRS ID {self.current_crs} is not valid.")
        print(f"CRS is valid: {crs.authid()}") # Debugging
        return crs

    @classmethod
    def name(cls) -> str:
        return "PandapowerProvider"

    @classmethod
    def description(cls) -> str:
        """Returns the memory provider description"""
        return "PandapowerProvider"

    def extent(self) -> QgsRectangle:
        """Calculates the extent of the bend and returns a QgsRectangle"""
        if not self._extent:
            try:
                min_x = float('inf')
                max_x = float('-inf')
                min_y = float('inf')
                max_y = float('-inf')

                #df_geodata = getattr(self.net, f'{self.network_type}_geodata')
                df_geodata = getattr(self.net, f'{self.network_type}').geo
                if df_geodata is None or df_geodata.empty:
                    return QgsRectangle()

                # Point geometry (bus/junction)
                if self.network_type in ['bus', 'junction']:
                    '''
                    min_x = df_geodata['x'].min()
                    max_x = df_geodata['x'].max()
                    min_y = df_geodata['y'].min()
                    max_y = df_geodata['y'].max()
                    '''
                    for idx, geo_str in df_geodata.items():
                        try:
                            if geo_str:
                                geo_data = json.loads(geo_str)
                                if ('coordinates' in geo_data and isinstance(geo_data['coordinates'], list)
                                        and len(geo_data['coordinates']) == 2):
                                    x = geo_data['coordinates'][0]
                                    y = geo_data['coordinates'][1]
                                    min_x = min(min_x, x)
                                    max_x = max(max_x, x)
                                    min_y = min(min_y, y)
                                    max_y = max(max_y, y)
                                else:
                                    print(f"Incorrect coordinate format for {self.network_type}.")
                                    return
                        except Exception as e:
                            print(f"Warning: Bus/Junction data of index {idx} failed to produce: {str(e)}")

                # Line geometry (line/pipe)
                elif self.network_type in ['line', 'pipe']:
                    # Iterate through the coordinates of each line
                    '''
                    for _, row in df_geodata.iterrows():
                        coords = row.get('coords', [])
                        if coords:
                            # coords is already in the form of a list of (x, y) pairs
                            for x, y in coords:
                                min_x = min(min_x, x)
                                max_x = max(max_x, x)
                                min_y = min(min_y, y)
                                max_y = max(max_y, y)
                    '''
                    for idx, geo_str in df_geodata.items():
                        try:
                            if geo_str:
                                geo_data = json.loads(geo_str)
                                if 'coordinates' in geo_data and isinstance(geo_data['coordinates'], list):
                                    for coord_pair in geo_data['coordinates']:
                                        if isinstance(coord_pair, list) and len(coord_pair) == 2:
                                            x, y = coord_pair[0], coord_pair[1]
                                            min_x = min(min_x, x)
                                            max_x = max(max_x, x)
                                            min_y = min(min_y, y)
                                            max_y = max(max_y, y)
                                        else:
                                            print(f"Incorrect coordinate format for {self.network_type}.")
                                            return
                        except Exception as e:
                            print(f"Warning: Lind/Pipe data of index {idx} failed to produce: {str(e)}")

                # Check if the valid range has been calculated
                if min_x == float('inf') or max_x == float('-inf'):
                    print("Warning: extent is infinite.")
                    return QgsRectangle()

                return QgsRectangle(min_x, min_y, max_x, max_y)

            except Exception as e:
                self.pushError(f"Error calculating extent: {str(e)}")
                import traceback
                traceback.print_exc()
                return QgsRectangle()

    def featureCount(self):
        """
        Returns the number of features in the provider.

        :return: Number of features
        :rtype: int
        """
        try:
            return len(self.df)
        except Exception as e:
            self.pushError(f"Failed to count features: {str(e)}")
            return 0

    def featureSource(self):
        return pandapower_feature_source.PandapowerFeatureSource(self)

    def isValid(self):
        """
        Return the validity of the data provider.
        """
        return self._is_valid

    def storageType(self):
        """
        Returns the permanent storage type for this layer as a friendly name.
        """
        return f"{self.network_type} layer is Pandapower Network in json format"

    def wkbType(self):
        if self.network_type == 'bus' or self.network_type == 'junction':
            return QgsWkbTypes.Point
        elif self.network_type == 'line' or self.network_type == 'pipe':
            return QgsWkbTypes.LineString

    def unload(self):
        # Remove from listener
        NetworkContainer.remove_listener(self.uri, self)
        # Wait until the running save thread completes
        if self._save_thread and self._save_thread.isRunning():
            self._save_thread.wait()
        # Remove custom data provider when it is deleted
        QgsProviderRegistry.instance().removeProvider('PandapowerProvider')